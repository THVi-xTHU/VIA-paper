\section{Method}
\subsection{Problem Formulation}
The main difficulties for the blind people to cross the street include: 1) to find the direction to go; 2) to recognize the  traffic lights; 3) to distinguish and avoid obstacles through the road. In response to these problems, we have given corresponding solutions. The system is dedicated to be deployed in the form of smart glasses.

\para{Direction to go.} Modern smart phones already include sophisticated maps and navigation solutions. In order to guide the blind correctly, we ensure that the GPS of the smart glasses always points to the front of the blind person. Therefore, regardless of how the blind walks to the intersection, the path plan generated by the navigation app enables the blind person to roughly know the direction of the road he wants to cross.

\para{Recognition of traffic lights.} It is necessary to be aware of the traffic light status before crossing the road. Generally, the solution to the task is broken down into two parts: firstly to detect the position of the traffic light in the image; secondly to identify the light color in corresponding areas. Recently, to propel the development of automated driving, researchers have annotated an amount of datasets, including traffic signs, traffic lights, vehicles and pedestrians on road. Therefore, it's feasible to use a learning-based detection algorithm to detect the traffic lights. 

Inevitably, an image captured by an RGB camera may conclude multiple traffic lights. The problem of distinguishing the correct pedestrian light is not within the consideration of automated driving, but is indeed significant in our application. Unfortunately, the standard for the traffic lights in different countries is not unified. For instance, China uses the human figures to represent pedestrian lights, and the arrow figures to indicate left turn or right turn; While in the USA, both pedestrian lights and car lights are all indicated by red or green circular figures, which makes it difficult to directly differentiate the pedestrian light from shape. Nevertheless, we assume that there are zebra crossings  on city roads, so the traffic lights on the opposite side of the zebra crossing should be pedestrian lights. Thus, by detecting zebra lines on road, we use this intuition in our algorithms to identify pedestrian and non-pedestrian lights.

\para{Obstacle avoidance.} Even if green lights turns on, it doesn't mean that the blind can cross the road right away. There are always pedestrians from same or opposite sides walking back and forth; and it is possible that some vehicles are also making the left/right turn simultaneously, since that in certain countries, the left or right turn for the motor vehicles are not ruled by the traffic light; More commonly, non-motorized vehicles are also running on the non-motorized lanes on both sides. If not getting notified of how to avoid these obstacles in time, blind people will be in risk to walk through. Our solution is to first use the detection algorithm to obtain the position of obstacles in view, and secondly to obtain the distance between each obstacle and the blind by monocular or binocular depth estimation algorithms. Moreover, if we can predict the motion of the obstacle in future, we will be able to better decide whether to stop or keep forwarding, so we also track the route of the obstructive objects in view.

\subsection{Robust traffic light detection and tracking}
\para{Detection.} Modern object detectors are easily adapted to road scene by training with automated datasets such as  YOLOv3~\cite{redmon-farhadi:2018}



\para{HSV-based light color classifier.}
%1.红绿灯检测到后，另一个重要问题是对于灯的颜色分类
%2.HSV相比于RGB的优势
%3.我们的实现方式
Once the traffic lights are detected, another important task is to classify the color of detected traffic lights. Wang et al. \cite{wang-et-al:2014} use RGB coloring space to perform the color segmentation.


Although RGB is a direct representation of color, the R, G, and B values are not directly related to the three attributes of color and cannot reveal the relationship between colors.
Therefore, we use a HSV-based method to build our light color classifier for determining the active state of traffic lights. HSV stands for "Hue, Saturation, Value", which is used to measure the hue angle of a color, saturation and brightness. In HSV color space, by counting the pixels inside a given slice of color and then filtering for a dynamically set saturation threshold, we can detect whether the target region is predominantly red, green or neither.
% TODO 2013 RGB-D image-based detection of stairs, pedestrian crosswalks and traffic signs


First, the average saturation in the target region is determined. Second, we get the upper bound and lower bound of the H-channel range for each color, according to the saturation threshold. Third, we set the lower bound of brightness, since it is a major feature distinguishing background noise, such as tree and leaves, with the actual green "light". Once the bounds are settled, the next step is to create a mask by finding all pixels in the target HSV image that are within the bounds. Each color state has its corresponding bitwise masks. Now, we can have a nicely quantified representation of the color of the traffic light by comparing the total number of non-zero pixels in the mask. The color state with largest number of non-zero pixels is selected as the light state.


\para{Tracking.} At a spacious crossroad, the traffic lights observed are usually small. Even the most recent detectors can have a certain number of miss detections. Performing tracking on the detected targets can partly alleviate the problem. However, since most visual tracking algorithms~\cite{henriques-et-al:2015,nam-han:2016,bertinetto-et-al:2016,held-et-al:2016} find the targets according to the templates generated from previous frames, it is prone to deviation in history. If not proper dealt with, the tracker will finally lose the target. In fact, general visual trackers don't know what are the objects they are tracking on, so this drives us to use the detection algorithm to compensate for the tracking drift. The framework integrating the advantages of detection and tracking is named \emph{track-to-detect} and \emph{detect-to-track}.


    The tracking of traffic lights in a short term are relative simple, because 1) the the shape of the lights are rigid; 2) the distribution of lights in view is sparse; 3) the height makes them seldom suffer from occlusion. Consequently, we adopt KCF~\cite{henriques-et-al:2015} as the tracker. KCF is good enough to meet the demands, and it runs at over 200 fps on CPUs so it will not encumber the real-time speed in our system. Once a traffic light is detected, a KCF tracker is assigned to it. The tracker uses the traffic light patch of the previous frame as a template, and find the maximum correlation pixel location in the search area of the current frame relative to the template. 
  
 

We maintain a tracker set $\mathcal{T}$ to save all trackers in history, and notate the set of current active trackers as $\mathcal{T}_a \in \mathcal{T}$. We denote the traffic light detection box on frame $n$ as $d_{tl}^{n_i}, i=1,\cdots, k$, and the active tracker predicted bounding boxes on frame $n$ as $t_{tl}^{n_j}, j=1,\cdots, |\mathcal{T}_a|$. Afterwards, the tracker predicted boxes $t_{tl}^{n_j}$ are matched to detection boxes $d_{tl}^{n_i}$ using Hungarian algorithm~\cite{kuhn-munkres:1955} according to the intersection-over-union(IOU) between bounding boxes. If the IOU is larger than a minimum value $\theta$, the two boxes are merged into one, and the current location of the tracker is rectified by the respective detection box. Otherwise, the detection box is regarded as a new target to be added into tracker set $\mathcal{T}$, and the tracker predicted box indicates there is a miss detection of the target in this frame, which should be punished in case the target light has exited the view.
 
In each frame, there might be multiple detection and tracking boxes that belong to a single traffic light. Keeping these duplicates would harm the tracking  thus  before matching, we use non-maximum-suppression (NMS) on both detection boxes and tracker predicted boxes to reduce the deleterious duplicates. We prefer to remove the detection duplicates with lower detection scores, while in the filtering of the repeated tracking box, we comprehensively consider the IOU w.r.t the corresponding detection box, their detection scores and tracking scores.

\para{Active tracker selection.} The detector sometimes produces false alarms. We use the following strategies to reduce the false alarm rate: 1) only when a new detection is continuously detected 3 times, it is considered as \emph{qualified}, and is added into the active set $\mathcal{T}_a$; 2) each time when a tracked target is detected, it's life confidence increase, and vice versa; 3) if the life confidence of a tracker is below some threshold, it is considered as \emph{outdated}. We remove these trackers from $\mathcal{T}_a$. 

Finally, the output traffic light for a frame is the summation of detection and tracking results. The procedure of the algorithm is referred at Algorithm~\ref{alg:traffic_light}.   

\begin{algorithm}[ht!]
\caption{Robust Traffic Light Detection and Tracking} 
\label{alg:traffic_light}
\begin{algorithmic}[1]
\State $I^n$: Input image at frame $n$
\State $\theta$: IOU threshold of matching
\State $\mathcal{T} = \emptyset, \mathcal{T}_a = \emptyset$ 
\Procedure{RobustTrafficLightDetection}{$I^n, \theta$}
\State $O \Leftarrow \emptyset$
\State $d^{n}, s^{n} \Leftarrow Detector(I^n)$
\State $d_{tl}^{n}, s_{tl}^{n} \Leftarrow$ pick the detection of traffic light from $d^{n}$
%\IF{$n < 0$} 
%\STATE $X \Leftarrow 1 / x$ 
%\STATE $N \Leftarrow -n$ 
%\ELSE 
%\STATE $X \Leftarrow x$ 
%\STATE $N \Leftarrow n$
%\ENDIF 
\For{each tracker $T_i$ in $\mathcal{T}_a$} 
\State $t_{tl}^{n_i}, {s'}_{tl}^{n_i} \Leftarrow  t_{tl}^{(n-1)_i}.predict()$
\EndFor 
\State $d_{tl}^{n_{i'}} \Leftarrow NMS(d_{tl}^{n_i}, s_{tl}^{n_i})$
\State ${s'}_{tl}^{n_{j}} = Merge(IOU_{ij}, s_{tl}^n, {s'}_{tl}^n)$, $t_{tl}^{n_{j'}} \Leftarrow NMS(t_{tl}^{n_j}, {s'}_{tl}^{n_j})$
\State $\mathcal{M} \Leftarrow []_{|n_{i'}| \times |n_{j'}|}$
\For{each detection $d_{tl}^i$ in $d_{tl}^{n_{i'}}$}
\For{each tracker predicted box $t_{tl}^j$ in $t_{tl}^{n_{j'}}$}
\State $M[i, j] = IOU(d_{tl}^i, t_{tl}^j$)
\EndFor
\EndFor
\State $ P \Leftarrow Hungarian(M, \theta)$
\For{each pair $(d_{tl}^i, t_{tl}^j)$ in P}
\State tracker $T^j.update(d_{tl}^i)$
\State $O.insert(d_{tl}^i)$
\EndFor

\For{each detection $d_{tl}^i$ not in Row(P)}
\State tracker $ T_{new} \Leftarrow \mathcal{T}.insert(d_{tl}^i)$
\State $T_{new}.update()$; $O.insert(d_{tl}^i)$
\EndFor
\For{each tracker predicted box $t_{tl}^j$ not in Col(P)}
\State $T^j.punish()$; $O.insert(t_{tl}^j)$
\EndFor
\For{each tracker $T_i$ in $\mathcal{T}$}
\If{$T_i$.qualified()}
\State $\mathcal{T}_a.insert(T_i)$ 
\EndIf
\If{$T_i$.outdated()}
\State $\mathcal{T}_a.remove(T_i)$
\EndIf
\EndFor
\Return $O$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Pedestrian light determination}
%0.Related Works
%1.为什么需要斑马线识别？因为在复杂道路场景下，同时有vehicle lights和pedestrian lights，可以通过斑马线的位置来辅助定位红绿灯
%2.怎样实现斑马线检测的？
%\para{Zebra crossing detection for determining pedestrian light.}

Traffic lights are the most important signalling devices positioned at road intersections, guiding the motion of both the vehicles and the pedestrians. When visually imparied pedestrians cross the road, the detection of the existence and the status of all the traffic lights are necessary. Especially, pedestrian lights play a vital role in the entire incident, which dominate the major decisions of our vision-based road-crossing assistant. Therefore, we need to determine the pedestrian light among all the detected traffic lights.



\para{Zebra crossing detection} In complex urban road scenes, with both vehicle lights and pedestrian lights, the detection of the zebra crossing can help determine the target pedestrian light among all the candidate lights. Since the pedestrian lights are positioned at the end of zebra crossing, we first need to detect a trapezoidal ROI of zebra crossing. Then the edges and the vanishing point of the zebra crossing are extracted for determining the pedestrian light. 


In our proposed vision-based assistant, zebra crossing detection is implemented as follows. First, the white color is extracted as a mask according to a set threshold. Second, the mask is eroded to get the contours of white strips. Some contours are filtered out by the shape information. Third, we calculate the median average for both left line and right line of zebra crossing. A RANSAC algorithm is performed to select the bounding points of a contour enclosed within the median circle. Finally, the bounding lines and the vanishing point of zebra crossing are derived, which gives the ROI of detection.

\begin{figure}[ht!]
\begin{center}
\begin{subfigure}[h]{0.48\linewidth}
 \includegraphics[width=1.\linewidth]{figure/zebra1.jpg}
 \caption{}
 \label{fig:zebra1}
 \end{subfigure}
 \begin{subfigure}[h]{0.48\linewidth}
  \includegraphics[width=1.\linewidth]{figure/zebra2.jpg}
  \caption{}
  \label{fig:zebra2}
  \end{subfigure}
   \begin{subfigure}[h]{0.48\linewidth}
  \includegraphics[width=1.\linewidth]{figure/zebra3.jpg}
  \caption{}
  \label{fig:zebra3}
  \end{subfigure}
  \begin{subfigure}[h]{0.48\linewidth}
  \includegraphics[width=1.\linewidth]{figure/zebra3.jpg}
  \caption{}
  \label{fig:zebra4}
  \end{subfigure}
\end{center}
   \caption{The figures demonstrate the relationship between the vanishing point of zebra crossing and the pedestrian light. (a) $y > h/2$, the pedestrian light is beyond the triangular area but closet to the vanishing point. (b) $y < h/2$, the pedestrian light is located in the triangular area and with largest $y$ coordinate. (c) vehicles occlude the zebra crossing slightly, noises are tolerated by RANSAC. (d) vehicles occlude the zebra crossing largely, the vanishing point is misleading.}
\label{fig:zebra}
\end{figure}
\para{Pedestrian light voting.} The vanishing point of the zebra crossing is closely related to the position of the pedestrian light. Assuming that the zebra crossing is successfully detected and a reasonable vanishing point is formed, we find: 
\begin{itemize}
\item if there is no traffic light in the triangle area, the pedestrian light is generally closer to the vanishing point than other traffic lights, as shown in Figure~\ref{fig:zebra1}.
\item if there are traffic lights existing in the triangular area formed by the vanishing point and the last zebra line, these lights must include the expected pedestrian light, and the pedestrian light is closest to the ground, as shown in Figure~\ref{fig:zebra2}; 
\end{itemize}

Based on the two phenomena we observed, we have made the following algorithm. Firstly we set the upper left corner of the image to the origin of the coordinate system, with the $y$ axis pointing down and the $x$ axis pointing right. We also denote the width and height of the image as $w, h$. Secondly, we check whether there is a stable zebra detection. If no stable zebra is detected, we give no voting with respect to the detected traffic lights. This conservative strategy requires more frames to determine pedestrian lights, but it will minimize the occurrence of errors. For example, when people and cars cross the sidewalk, they tend to occlude the zebra crossings partially. The occlusion is likely to cause the system to erroneously estimate the vanishing point and determinate a fake pedestrian light, as shown in Figure~\ref{fig:zebra3}. Thus, we drop the unstable frames and stay waiting for a reliable result. Thirdly, when a traffic light get 90\% of $\eta(\eta\ge 30)$ votes and it has larger votes than all other competitors, we believe it is a pedestrian light. If the status of the light is green, the blind start to cross the road.

It's possible that the old pedestrian light can disappear from the view, and after a duration it is removed from active traffic light set, as depicted in Algorithm~\ref{alg:traffic_light}. Our system can adapt to the dynamic switching between pedestrian lights. Once the existing pedestrian light is exceeded by other higher traffic lights or no longer valid, a new pedestrian light is elected to replace the old pedestrian light.



\subsection{Obstacle Avoidance}
Much of the previous work was limited to studying how to detect traffic lights and zebra crossings. However, to design a robust auxiliary system, obstacle avoidance is a problem that must be solved. Detection algorithms provide us with the obstacle location and categorical information on a two-dimensional plane. We need to estimate which obstacles are threatening to the blind and which are negligible. Thus, we combine a depth estimation algorithm based on either single or binocular cameras and trajectory prediction of obstacles (pedestrians, vehicles) to help the system identify threatened obstacles.


\para{RGB-camera depth estimation.}
Estimating scene depth from single image has become a popular research field~\cite{}. From a common sense perspective, it is impossible to accurately estimate the distance of a three-dimensional world object by one eye, but a relatively rough distance can be obtained from image information. This is the case with depth estimation algorithms based on deep learning.




\para{Stereo-camera depth estimation.}



\subsection{Finite State Decision System}
%The deviation during forwarding would be reminded if the user is offset from the original set path and orientation.

\begin{figure}[t]
\begin{center}
 \includegraphics[width=1.\linewidth]{figure/fsm_state.jpeg}
\end{center}
   \caption{The state transmission during crossing.}
\label{fig:fsm}
\end{figure}
The state of this system is shown in Figure~\ref{fig:fsm}. We assume that the GPS would guide the blind to walk in a correct direction. Thus, deviation is not in consideration of the vision system. 
\begin{itemize}
\item \textbf{Light Waiting}. To begin with, a blind stands at a crossroad, with his face heading in the direction to go. The system is initialized at \emph{Light Waiting} stage and starts to search for a pedestrian light in view. When a pedestrian light is selected, the system waits until the pedestrian light turns green. Once the green light shows, the system enters the \emph{Prepare Forwarding} stage.
\item \textbf{Prepare Forwarding.} The blind keeps waiting in this stage until there is no close obstacle around. If the red light happens to show during waiting, the system returns to the \emph{Light Waiting} stage. Otherwise, when all obstacles are distant, the blind begins to cross the road and the status is marked as \emph{Crossing Road}. 
\item \textbf{Crossing Road.} In this stage, the user keeps walking, however when the blind encounters close obstacles, the system turns into \emph{Crossing Suspended} stage; when  the green light turns red during crossing, the system will stay in the stage but hasten the blind to pick up speed. 
\item \textbf{Crossing Suspended.} The user stands by in this status. When all obstacles move away, the system returns to the \emph{Crossing Road} stage and the blind continues to forward. When there is no traffic light in view, it indicates the blind has reached the opposite side of the road. Finally, the status is updated to \emph{Arrival}.
\item \textbf{Arrival.} When the user reaches the opposite sidewalk, the system can guide him along the planed path until meeting the next crossing. 
\end{itemize}



%\subsection{Detection}
%\subsubsection{One-stage end-to-end detection method}
%\subsubsection{HSV-based light color classifier}
%\subsection{Determination}
%\subsubsection{Zebra crossing detection for determining pedestrian light
%}
%\subsection{Tracking}
%\subsubsection{KCF tracker}
%\subsubsection{Detect to Track and Track to Detect}
%\section{Obstacle detection and tracking}
%\subsection{Depth-based global coordinate estimation}
%\subsection{Obstacle motion analysis}
%