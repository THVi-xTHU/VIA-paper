\section{Method}
\subsection{Problem Formulation}
The main difficulties for the blind people to cross the street include: 1) to find the direction to go; 2) to recognize the  traffic lights; 3) to distinguish and avoid obstacles through the road. In response to these problems, we have given corresponding solutions. The system is dedicated to be deployed in the form of smart glasses.

\para{Direction to go.} Modern smart phones already include sophisticated maps and navigation solutions. In order to guide the blind correctly, we ensure that the GPS of the smart glasses always points to the front of the blind person. Therefore, regardless of how the blind walks to the intersection, the path plan generated by the navigation app enables the blind person to roughly know the direction of the road he wants to cross.

\para{Recognition of traffic lights.} It is necessary to be aware of the traffic light status before crossing the road. Generally, the solution to the task is broken down into two parts: firstly to detect the position of the traffic light in the image; secondly to identify the light color in corresponding areas. Recently, to propel the development of automated driving, researchers have annotated an amount of datasets, including traffic signs, traffic lights, vehicles and pedestrians on road. Therefore, it's feasible to use a learning-based detection algorithm to detect the traffic lights. 

Inevitably, an image captured by an RGB camera may conclude multiple traffic lights. The problem of distinguishing the correct pedestrian light is not within the consideration of automated driving, but is indeed significant in our application. Unfortunately, the standard for the traffic lights in different countries is not unified. For instance, China uses the human figures to represent pedestrian lights, and the arrow figures to indicate left turn or right turn; While in the USA, both pedestrian lights and car lights are all indicated by red or green circular figures, which makes it difficult to directly differentiate the pedestrian light from shape. Nevertheless, we assume that there are zebra crossings  on city roads, so the traffic lights on the opposite side of the zebra crossing should be pedestrian lights. Thus, by detecting zebra lines on road, we use this intuition in our algorithms to identify pedestrian and non-pedestrian lights.

\para{Obstacle avoidance.} Even if green lights turns on, it doesn't mean that the blind can cross the road right away. There are always pedestrians from same or opposite sides walking back and forth; and it is possible that some vehicles are also making the left/right turn simultaneously, since that in certain countries, the left or right turn for the motor vehicles are not ruled by the traffic light; More commonly, non-motorized vehicles are also running on the non-motorized lanes on both sides. If not getting notified of how to avoid these obstacles in time, blind people will be in risk to walk through. Our solution is to first use the detection algorithm to obtain the position of obstacles in view, and secondly to obtain the distance between each obstacle and the blind by monocular or binocular depth estimation algorithms. Moreover, if we can predict the motion of the obstacle in future, we will be able to better decide whether to stop or keep forwarding, so we also track the route of the obstructive objects in view.

\subsection{Robust pedestrian light detection and tracking}
\para{Detection.} Modern object detectors are easily adapted to road scene by training with automated datasets such as  YOLOv3~\cite{redmon-farhadi:2018}

\para{Tracking.} The traffic lights across the road that are observed from the side of the road are often very small, so even the most recent detectors will have some degree of missed detection. We track traffic lights to make up for these missed checks. We track it with KCF~\cite{kcf} because it can reach 200fps on the CPU and it will not affect real-time performance in our system. The KCF uses the traffic light image of the previous frame as a template, and uses the correlation filter in the search area at the same position in the current frame to find the maximum position relative to the template frame.


\para{Zebra-crossing detection.}

\para{Pedestrian light voting.}
%\subsection{Detection}
%\subsubsection{One-stage end-to-end detection method}
%\subsubsection{HSV-based light color classifier}
%\subsection{Determination}
%\subsubsection{Zebra crossing detection for determining pedestrian light
%}
%\subsection{Tracking}
%\subsubsection{KCF tracker}
%\subsubsection{Detect to Track and Track to Detect}
%\section{Obstacle detection and tracking}
%\subsection{Depth-based global coordinate estimation}
%\subsection{Obstacle motion analysis}
%