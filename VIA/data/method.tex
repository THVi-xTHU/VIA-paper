\section{Method}
\subsection{Problem Formulation}
The main difficulties for the blind people to cross the street include: 1) to find the direction to go; 2) to recognize the  traffic lights; 3) to distinguish and avoid obstacles through the road. In response to these problems, we have given corresponding solutions. The system is dedicated to be deployed in the form of smart glasses.

\para{Direction to go.} Modern smart phones already include sophisticated maps and navigation solutions. In order to guide the blind correctly, we ensure that the GPS of the smart glasses always points to the front of the blind person. Therefore, regardless of how the blind walks to the intersection, the path plan generated by the navigation app enables the blind person to roughly know the direction of the road he wants to cross.

\para{Recognition of traffic lights.} It is necessary to be aware of the traffic light status before crossing the road. Generally, the solution to the task is broken down into two parts: firstly to detect the position of the traffic light in the image; secondly to identify the light color in corresponding areas. Recently, to propel the development of automated driving, researchers have annotated an amount of datasets, including traffic signs, traffic lights, vehicles and pedestrians on road. Therefore, it's feasible to use a learning-based detection algorithm to detect the traffic lights. 

Inevitably, an image captured by an RGB camera may conclude multiple traffic lights. The problem of distinguishing the correct pedestrian light is not within the consideration of automated driving, but is indeed significant in our application. Unfortunately, the standard for the traffic lights in different countries is not unified. For instance, China uses the human figures to represent pedestrian lights, and the arrow figures to indicate left turn or right turn; While in the USA, both pedestrian lights and car lights are all indicated by red or green circular figures, which makes it difficult to directly differentiate the pedestrian light from shape. Nevertheless, we assume that there are zebra crossings  on city roads, so the traffic lights on the opposite side of the zebra crossing should be pedestrian lights. Thus, by detecting zebra lines on road, we use this intuition in our algorithms to identify pedestrian and non-pedestrian lights.

\para{Obstacle avoidance.} Even if green lights turns on, it doesn't mean that the blind can cross the road right away. There are always pedestrians from same or opposite sides walking back and forth; and it is possible that some vehicles are also making the left/right turn simultaneously, since that in certain countries, the left or right turn for the motor vehicles are not ruled by the traffic light; More commonly, non-motorized vehicles are also running on the non-motorized lanes on both sides. If not getting notified of how to avoid these obstacles in time, blind people will be in risk to walk through. Our solution is to first use the detection algorithm to obtain the position of obstacles in view, and secondly to obtain the distance between each obstacle and the blind by monocular or binocular depth estimation algorithms. Moreover, if we can predict the motion of the obstacle in future, we will be able to better decide whether to stop or keep forwarding, so we also track the route of the obstructive objects in view.

\subsection{Robust pedestrian light detection and tracking}
\para{Detection.} Modern object detectors are easily adapted to road scene by training with automated datasets such as  YOLOv3~\cite{redmon-farhadi:2018}



\para{HSV-based light color classifier.}
%1.红绿灯检测到后，另一个重要问题是对于灯的颜色分类
%2.HSV相比于RGB的优势
%3.我们的实现方式
Once the traffic lights are detected, another important task is to classify the color of detected traffic lights. Wang et al. \cite{wang-et-al:2014} use RGB coloring space to perform the color segmentation.


Although RGB is a direct representation of color, the R, G, and B values are not directly related to the three attributes of color and cannot reveal the relationship between colors.
Therefore, we use a HSV-based method to build our light color classifier for determining the active state of traffic lights. HSV stands for "Hue, Saturation, Value", which is used to measure the hue angle of a color, saturation and brightness. In HSV color space, by counting the pixels inside a given slice of color and then filtering for a dynamically set saturation threshold, we can detect whether the target region is predominantly red, green or neither.
% TODO 2013 RGB-D image-based detection of stairs, pedestrian crosswalks and traffic signs


First, the average saturation in the target region is determined. Second, we get the upper bound and lower bound of the H-channel range for each color, according to the saturation threshold. Third, we set the lower bound of brightness, since it is a major feature distinguishing background noise, such as tree and leaves, with the actual green "light". Once the bounds are settled, the next step is to create a mask by finding all pixels in the target HSV image that are within the bounds. Each color state has its corresponding bitwise masks. Now, we can have a nicely quantified representation of the color of the traffic light by comparing the total number of non-zero pixels in the mask. The color state with largest number of non-zero pixels is selected as the light state.


\para{Tracking.} At a spacious crossroad, the traffic lights observed are usually small. Even the most recent detectors can have a certain number of miss detections. Performing tracking on the detected targets can partly alleviate the problem. However, since most visual tracking algorithms~\cite{henriques-et-al:2015,nam-han:2016,bertinetto-et-al:2016,held-et-al:2016} find the targets according to the templates generated from previous frames, it is prone to deviation in history. If not proper dealt with, the tracker will finally lose the target. In fact, general visual trackers don't know what are the objects they are tracking on, so this drives us to use the detection algorithm to compensate for the tracking drift. The framework integrating the advantages of detection and tracking is named \emph{track-to-detect} and \emph{detect-to-track}.


    The tracking of traffic lights in a short term are relative simple, because 1) the the shape of the lights are rigid; 2) the distribution of lights in view is sparse; 3) the height makes them seldom suffer from occlusion. Consequently, we adopt KCF~\cite{henriques-et-al:2015} as the tracker. KCF is good enough to meet the demands, and it runs at over 200 fps on CPUs so it will not encumber the real-time speed in our system. Once a traffic light is detected, a KCF tracker is assigned to it. The tracker uses the traffic light patch of the previous frame as a template, and find the maximum correlation pixel location in the search area of the current frame relative to the template. 
  
 

We maintain a tracker set $\mathcal{T}$ to save all trackers in history, and notate the set of current active trackers as $\mathcal{T}_a \in \mathcal{T}$. We denote the traffic light detection box on frame $n$ as $d_{tl}^{n_i}, i=1,\cdots, k$, and the active tracker predicted bounding boxes on frame $n$ as $t_{tl}^{n_j}, j=1,\cdots, |\mathcal{T}_a|$. Afterwards, the tracker predicted boxes $t_{tl}^{n_j}$ are matched to detection boxes $d_{tl}^{n_i}$ using Hungarian algorithm~\cite{kuhn-munkres:1955} according to the intersection-over-union(IOU) between bounding boxes. If the IOU is larger than a minimum value $\theta$, the two boxes are merged into one, and the current location of the tracker is rectified by the respective detection box. Otherwise, the detection box is regarded as a new target to be added into tracker set $\mathcal{T}$, and the tracker predicted box indicates there is a miss detection of the target in this frame, which should be punished in case the target light has exited the view.
 
In each frame, there might be multiple detection and tracking boxes that belong to a single traffic light. Keeping these duplicates would harm the tracking  thus  before matching, we use non-maximum-suppression (NMS) on both detection boxes and tracker predicted boxes to reduce the deleterious duplicates. We prefer to remove the detection duplicates with lower detection scores, while in the filtering of the repeated tracking box, we comprehensively consider the IOU w.r.t the corresponding detection box, their detection scores and tracking scores.

\para{Active tracker selection.} The detector sometimes produces false alarms. We use the following strategies to reduce the false alarm rate: 1) only when a new detection is continuously detected 3 times, it is considered as \emph{qualified}, and is added into the active set $\mathcal{T}_a$; 2) each time when a tracked target is detected, it's life confidence increase, and vice versa; 3) if the life confidence of a tracker is below some threshold, it is considered as \emph{outdated}. We remove these trackers from $\mathcal{T}_a$. 

Finally, the output traffic light for a frame is the summation of detection and tracking results. The procedure of the algorithm is referred at Algorithm~\ref{alg:traffic_light}.   

\begin{algorithm}[H]
\caption{Robust Traffic Light Detection and Tracking} 
\label{alg:traffic_light}
\begin{algorithmic}[1]
\State $I^n$: Input image at frame $n$
\State $\theta$: IOU threshold of matching
\State $\mathcal{T} = \emptyset, \mathcal{T}_a = \emptyset$ 
\Procedure{RobustTrafficLightDetection}{$I^n, \theta$}
\State $O \Leftarrow \emptyset$
\State $d^{n}, s^{n} \Leftarrow Detector(I^n)$
\State $d_{tl}^{n}, s_{tl}^{n} \Leftarrow$ pick the detection of traffic light from $d^{n}$
%\IF{$n < 0$} 
%\STATE $X \Leftarrow 1 / x$ 
%\STATE $N \Leftarrow -n$ 
%\ELSE 
%\STATE $X \Leftarrow x$ 
%\STATE $N \Leftarrow n$
%\ENDIF 
\For{each tracker $T_i$ in $\mathcal{T}_a$} 
\State $t_{tl}^{n_i}, {s'}_{tl}^{n_i} \Leftarrow  t_{tl}^{(n-1)_i}.predict()$
\EndFor 
\State $d_{tl}^{n_{i'}} \Leftarrow NMS(d_{tl}^{n_i}, s_{tl}^{n_i})$
\State ${s'}_{tl}^{n_{j}} = Merge(IOU_{ij}, s_{tl}^n, {s'}_{tl}^n)$, $t_{tl}^{n_{j'}} \Leftarrow NMS(t_{tl}^{n_j}, {s'}_{tl}^{n_j})$
\State $\mathcal{M} \Leftarrow []_{|n_{i'}| \times |n_{j'}|}$
\For{each detection $d_{tl}^i$ in $d_{tl}^{n_{i'}}$}
\For{each tracker predicted box $t_{tl}^j$ in $t_{tl}^{n_{j'}}$}
\State $M[i, j] = IOU(d_{tl}^i, t_{tl}^j$)
\EndFor
\EndFor
\State $ P \Leftarrow Hungarian(M, \theta)$
\For{each pair $(d_{tl}^i, t_{tl}^j)$ in P}
\State tracker $T^j.update(d_{tl}^i)$
\State $O.insert(d_{tl}^i)$
\EndFor

\For{each detection $d_{tl}^i$ not in Row(P)}
\State tracker $ T_{new} \Leftarrow \mathcal{T}.insert(d_{tl}^i)$
\State $T_{new}.update()$; $O.insert(d_{tl}^i)$
\EndFor
\For{each tracker predicted box $t_{tl}^j$ not in Col(P)}
\State $T^j.punish()$; $O.insert(t_{tl}^j)$
\EndFor
\For{each tracker $T_i$ in $\mathcal{T}$}
\If{$T_i$.qualified()}
\State $\mathcal{T}_a.insert(T_i)$ 
\EndIf
\If{$T_i$.outdated()}
\State $\mathcal{T}_a.remove(T_i)$
\EndIf
\EndFor
\Return $\mathcal{O}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\para{Pedestrian light voting.}



\para{Zebra crossing detection for determining pedestrian light.}
%0.Related Works
%1.为什么需要斑马线识别？因为在复杂道路场景下，同时有vehicle lights和pedestrian lights，可以通过斑马线的位置来辅助定位红绿灯
%2.怎样实现斑马线检测的？
Traffic lights are the most important signalling devices positioned at road intersections, guiding the motion of both the vehicles and the pedestrians. When visually imparied pedestrians cross the road, the detection of the existence and the status of all the traffic lights are necessary. Especially, pedestrian lights play a vital role in the entire incident, which dominate the major decisions of our vision-based road-crossing assistant. Therefore, we need to determine the pedestrian light among all the detected traffic lights.


In complex urban road scenes, with both vehicle lights and pedestrian lights, the detection of the zebra crossing can help determine the target pedestrian light among all the candidate lights. Since the pedestrian lights are positioned at the end of zebra crossing, we first need to detect a trapezoidal ROI of zebra crossing. Then the edges and the vanishing point of the zebra crossing are extracted for determining the pedestrian light. 


In our proposed vision-based assistant, zebra crossing detection is implemented as follows. First, the white color is extracted as a mask according to a set threshold. Second, the mask is eroded to get the contours of white strips. Some contours are filtered out by the shape information. Third, we calculate the median average for both left line and right line of zebra crossing. A RANSAC algorithm is performed to select the bounding points of a contour enclosed within the median circle. Finally, the bounding lines and the vanishing point of zebra crossing are derived, which gives the ROI of detection.




%\subsection{Detection}
%\subsubsection{One-stage end-to-end detection method}
%\subsubsection{HSV-based light color classifier}
%\subsection{Determination}
%\subsubsection{Zebra crossing detection for determining pedestrian light
%}
%\subsection{Tracking}
%\subsubsection{KCF tracker}
%\subsubsection{Detect to Track and Track to Detect}
%\section{Obstacle detection and tracking}
%\subsection{Depth-based global coordinate estimation}
%\subsection{Obstacle motion analysis}
%